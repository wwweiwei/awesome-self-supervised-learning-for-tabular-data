# Awesome Self-supervised Learning for Tabular Data
![Version](https://img.shields.io/badge/Version-1.0-lightgrey.svg) 
![LastUpdated](https://img.shields.io/badge/LastUpdated-2023.11-lightblue.svg)
![Topic](https://img.shields.io/badge/Topic-SSL%20for%20Tabular%20Data-pink?logo=github)

This repository contains the frontier research on **self-supervised learning** for tabular data which is a popular topic recently.<br>
This list is maintained by [Wei-Wei Du](https://wwweiwei.github.io/). (Actively keep updating)

## Papers
* [VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain (NeurIPS'20)](https://proceedings.neurips.cc/paper/2020/file/7d97667a3e056acab9aaf653807b4a03-Paper.pdf)
    *  [Supplementary](https://proceedings.neurips.cc/paper/2020/file/7d97667a3e056acab9aaf653807b4a03-Supplemental.pdf)
    *  [Code](https://github.com/jsyoon0823/VIME)
* [CORE: Self- and Semi-supervised Tabular Learning with COnditional REgularizations (NeurIPS'21)](https://sslneurips21.github.io/files/CameraReady/CORE_workshop.pdf)
* [SubTab: Subsetting Features of Tabular Data for Self-Supervised Representation Learning(NeurIPS'21)](https://arxiv.org/pdf/2110.04361.pdf)
    * [Supplementary](https://openreview.net/attachment?id=vrhNQ7aYSdr&name=supplementary_material)
    * [Code](https://github.com/AstraZeneca/SubTab)
* [SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption (ICLR'22 Spotlight)](https://arxiv.org/pdf/2106.15147.pdf)
* [STab: Self-supervised Learning for Tabular Data (NeurIPS'22 Workshop on Table Representation Learning)](https://openreview.net/pdf?id=EfR55bFcrcI)
* [SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training (NurIPSâ€˜22 Workshop on Table Representation Learning)](https://arxiv.org/pdf/2106.01342.pdf)
    * [Code](https://github.com/somepago/saint)
* [TabNet: Attentive Interpretable Tabular Learning (AAAI'21)](https://arxiv.org/abs/1908.07442)
    * [Code](https://github.com/dreamquark-ai/tabnet)
* [TabTransformer: Tabular Data Modeling Using Contextual Embeddings](https://arxiv.org/abs/2012.06678)
* [TransTab: Learning Transferable Tabular Transformers Across Tables (NeurIPS'22)](https://arxiv.org/abs/2205.09328)
    * [Code](https://github.com/RyanWangZf/transtab)
    * [Blog](https://realsunlab.medium.com/transtab-learning-transferable-tabular-transformers-across-tables-1e34eec161b8)
* [Self Supervised Pre-training for Large Scale Tabular Data (NeurIPS'22 TRL Workshop)](https://table-representation-learning.github.io/assets/papers/self_supervised_pre_training_f.pdf)
   * [Blog](https://www.amazon.science/publications/self-supervised-pre-training-for-large-scale-tabular-data)
* [XTab: Cross-table Pretraining for Tabular Transformers (ICML'23)](https://arxiv.org/abs/2305.06090)
* [Revisiting Self-Training with Regularized Pseudo-Labeling for Tabular Data](https://arxiv.org/abs/2302.14013)
* [DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource Real Estate Appraisal (CIKM'23)](https://arxiv.org/abs/2309.00855)
   * [Code](https://github.com/wwweiwei/DoRA)


#### Use correlation to capture relations between features
* [Self-Supervision Enhanced Feature Selection with Correlated Gates (ICLR'22)](https://openreview.net/pdf?id=oDFvtxzPOx)
    * [Code](https://github.com/chl8856/SEFS)
* [Local Contrastive Feature Learning for Tabular Data (CIKM'22)](https://dl.acm.org/doi/pdf/10.1145/3511808.3557630)

#### Use pretrained language model to learn better representation
* [TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data (ACL'20)](https://arxiv.org/abs/2005.08314)
* [LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks (NeurIPS'22)](https://arxiv.org/pdf/2206.06565.pdf)
    * [Code](https://github.com/UW-Madison-Lee-Lab/LanguageInterfacedFineTuning)
* [Pretrained Transformers As Universal Computation Engines](https://arxiv.org/pdf/2103.05247.pdf)
    * [Code](https://github.com/kzl/universal-computation)

## Tutorials
* [Self-Supervised Learning: Self-Prediction and Contrastive Learning (NeurIPS'21)](https://neurips.cc/virtual/2021/tutorial/21895)

## Related Survey
* [Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects](https://arxiv.org/abs/2306.10125)
* [Deep Neural Networks and Tabular Data: A Survey](https://arxiv.org/abs/2110.01889)
